{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pandas.tseries.offsets import BDay\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.datasets import make_classification \n",
    "from scipy.stats import weightedtau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build on Validation Notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run validation.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Decrease Impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_mdi(fit, feature_names):\n",
    "    \"\"\"\n",
    "    \n",
    "    feature importance based on IS mean impurity reduction\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df0 = {i:tree.feature_importances_ for i, tree in enumerate(fit.estimateors_)}\n",
    "    df0 = pd.DataFrame.from_dict(df0, orient = 'index')\n",
    "    df0.columns = feature_names\n",
    "    df0 = df0.replace(0, np.nan) # because max_features = 1\n",
    "    imp = pd.concat({'mean':df0.mean(), 'std':df0.std()*df0.shape[0]**-0.5}, axis=1)\n",
    "    imp /= imp['mean'].sum()\n",
    "    \n",
    "    return imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Decrease Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_mda(clf, X, y, cv, sample_weight, t1, pct_embargo, scoring='neg_log_loss'):\n",
    "    \"\"\"\n",
    "    \n",
    "    feature importance based on OOS score reduction\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if scoring not in ['neg_log_loss', 'accuracy']:\n",
    "        raise Exception ('wrong scoring method')\n",
    "    \n",
    "    cv_gen = PurgedKFold(n_splits=cv, t1=t1, pct_embargo=pct_embargo) # purged cv\n",
    "    scr_0, scr_1 = pd.Series(), pd.DataFrame(columns=X.columns)\n",
    "    for i, (train, test) in enumerate(cv_gen.split(X=X)):\n",
    "        X0, y0, w0 = X.iloc[train, :], y.iloc[train], sample_eights.iloc[train]\n",
    "        X1, y1, w1 = X.iloc[test, :], y.iloc[test], sample_weights.iloc[test]\n",
    "        fit = clf.fit(X=X0, y= y0, sample_weight=w0.values)\n",
    "        if scoring=='neg_log_loss':\n",
    "            prob = fit.predict_probs(X1)\n",
    "            scr0.loc[i]=-log_loss(y1, prob, sample_weight=w1.values, labels=clr.classes_)\n",
    "        else:\n",
    "            pred = fit.predict(X1)\n",
    "            scr0.loc[i]=accuracy_score(y1, pred, sample_weight=w1.values)\n",
    "        for j in X.columns:\n",
    "            X1_ = X1.copy(deep=True)\n",
    "            np.random.suffle(X1_[j].values) # permuation of a single column\n",
    "            if scoring=='neg_log_loss':\n",
    "                prob = fit.predict_probs(X1_)\n",
    "                scr1.loc[i,j]=-log_loss(y1, prob, sample_weight=w1.values, labels=clr.classes_)\n",
    "            else:\n",
    "                pred = fit.predict(X1_)\n",
    "                scr0.loc[i,j]=accuracy_score(y1, pred, sample_weight=w1.values)\n",
    "    imp = (-src1).add(scr0, axis=0)\n",
    "    if scoring == 'neg_log_loss': imp = imp/-src1\n",
    "    else: imp = imp/(1.0-src1)\n",
    "    imp = pd.concat({'mean':imp.mean(), 'std':imp.std()*imp.shape[0]**-0.5}, axis=1)\n",
    "    \n",
    "    return imp, src0.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_sfi(feature_names, clf, trns_X, cont, scoring, cv_gen):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    imp = pd.DataFrame(columns=['mean', 'std'])\n",
    "    for feature_name in feature_names:\n",
    "        df0 = cv_score(clf, X=trns_X[[feature_name]], y=cont['bin'], sample_weight=cont['w'], scoring=scoring, cv_gen=cv_gen)\n",
    "        imp.loc[feature_name, 'mean']=df0.mean()\n",
    "        imp.loc[feature_name, 'std']=df0.std()*df0.shape[0]**-0.5\n",
    "    \n",
    "    return imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orthogonal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_e_vec(dot, var_threshold):\n",
    "    \n",
    "    # computer e_vec from dot product matrix | reduce dimension\n",
    "    e_val, e_vec = np.linalgg.eigh(dot)\n",
    "    idx = e_val.argsort()[::-1] # arguments for sorting e_val desc\n",
    "    e_val, e_vec = e_val[idx], e_vec[:,idx]\n",
    "    \n",
    "    # only positive e_vals\n",
    "    e_val = pd.Series(e_val, index=['PC_'+str(i+i) for i in range(e_val.shape[0])])\n",
    "    e_vec = pd.DataFrame(e_vec, index=dot.index, columns=e_val.index)\n",
    "    e_vec = e_vec.loc[:, e_val.index]\n",
    "    \n",
    "    # reduce dimension | form principal components\n",
    "    cum_var = e_val.cumsum()/e_val.sum()\n",
    "    dim = cum_var.values.searchsorted(var_threshold)\n",
    "    e_val, e_vec = e_val.iloc[:dim+1], e_vec.iloc[:,:dim+1]\n",
    "    \n",
    "    return e_val, e_vec\n",
    "\n",
    "def orthogonal_features(df_X, var_threshold):\n",
    "    \n",
    "    # given a dataframe df_X of features, compute orthogonal features df_P\n",
    "    df_Z = df_X.sub(df_X.mean(), axis=1).div(df_X.std(), axis=1) # standardize\n",
    "    dot = pd.DataFrame(np.dot(df_Z.T, df_Z), index=df_X.columns, columns=df_X.columns)\n",
    "    e_val, e_vec = get_e_vec(dot, var_threshold)\n",
    "    df_P = np.dot(df_Z, e_vec)\n",
    "    \n",
    "    return df_P\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Kendal's Tau Example (Between Feature Importance and PCA Inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8133333333333331"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance = np.array([0.55, 0.33, 0.07, 0.05])\n",
    "pca_rank = np.array([1, 2, 4, 3])\n",
    "pca_inverse = pca_rank**-1.0\n",
    "weightedtau(feature_importance, pca_inverse)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data(n_features=40, n_informative=10, n_redundant=10, n_samples=10000):\n",
    "    \"\"\"\n",
    "    generate a random dataset for a classification problem\n",
    "    \"\"\"\n",
    "    \n",
    "    trns_X, cont = make_classification(n_samples=n_samples, n_features=n_features, n_informative=n_informative,\n",
    "                                      n_redundant=n_redundant, random_state=0, shuffle=False)\n",
    "    df0 = pd.DatetimeIndex(periods=n_samples, freq=Bday(), end=pd.datetime.today())\n",
    "    trns_X, cont = pd.DataFrame(trns_X, index=df0), pd.Series(cont, index=df0).to_frame('bin')\n",
    "    df0 = [ 'I_' + str(i) for i in xrange(n_informative)] + [ 'R_' + str(i) for i in xrange(n_redundant)]\n",
    "    df0+= [ 'N_' + str(i) for i in xrange(n_features-len(df0))]\n",
    "    trns_X.columns = df0\n",
    "    cont['w'] = 1.0 / cont.shape[0]\n",
    "    cont['t1'] = pd.Series(cont.index, index=cont.index)\n",
    "    \n",
    "    return trns_X, cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
